#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Update_or_Add_Document.py

åŠŸèƒ½ï¼š
- æŒ‰â€œæ–‡æ¡£åç§°â€åœ¨æœ¬åœ° SQLite è¡¨ `kb_documents` ä¸­æ£€ç´¢ï¼š
  - è‹¥å­˜åœ¨ï¼šå–å‡º document_idï¼Œè°ƒç”¨ Dify çš„â€œæ›´æ–°æ–‡æ¡£â€æ¥å£ï¼ˆæ”¯æŒæŒ‰æ–‡ä»¶æˆ–æ–‡æœ¬æ›´æ–°ï¼‰
  - è‹¥ä¸å­˜åœ¨ï¼šèµ°â€œæ–°è§„æ·»åŠ â€æµç¨‹ï¼Œå¹¶æŠŠè®°å½•å†™å…¥ `kb_documents`

ä¾èµ–ï¼š
- ä¸ Add_Document_enhanced.py å…±ç”¨åŒä¸€æ•°æ®åº“ï¼ˆåŒ…å« knowledgebase ä¸ kb_documents ä¸¤è¡¨ï¼‰
- ä½¿ç”¨ /console/api ç™»å½•è·å– access_tokenï¼›å¦‚æœä½ çš„ç¯å¢ƒç”¨ /v1 API Keyï¼Œè¯·è‡ªè¡Œæ”¹é€  headers

ç”¨æ³•ç¤ºä¾‹ï¼ˆæŒ‰æ–‡ä»¶æ›´æ–°/æ–°å»ºï¼‰ï¼š
  python3 Update_or_Add_Document.py <knowledgebase_key> --doc-name "äº§å“æ‰‹å†Œ-å®‰è£…" --file /path/to/manual.pdf \
    --base-url http://localhost/console/api --email you@example.com --password ****

ç”¨æ³•ç¤ºä¾‹ï¼ˆæŒ‰æ–‡æœ¬æ›´æ–°/æ–°å»ºï¼‰ï¼š
  python3 Update_or_Add_Document.py <knowledgebase_key> --doc-name "FAQ-æ’é”™" --text "è¿™é‡Œæ˜¯æ–°çš„FAQæ–‡æœ¬..." \
    --base-url http://localhost/console/api --email you@example.com --password ****
"""
import os
import argparse
import sqlite3
import requests
import httpx

# === é…ç½®åŒºï¼ˆä¸ä½ çš„ç¯å¢ƒä¿æŒä¸€è‡´ï¼‰ ===
KBDB_PATH = "/home/tei952/sayama/00.standard_and_tool/standards/ai_poc/AI_Powered_system_manager/project_data/project_config.db"

DOC_TABLE_SQL = """
CREATE TABLE IF NOT EXISTS kb_documents (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    kb_id TEXT NOT NULL,
    doc_id TEXT NOT NULL,
    doc_name TEXT,
    file_id TEXT,
    file_name TEXT,
    created_at TEXT DEFAULT (datetime('now'))
);
"""

def get_db_conn():
    os.makedirs(os.path.dirname(KBDB_PATH), exist_ok=True)
    return sqlite3.connect(KBDB_PATH)

def init_db():
    conn = get_db_conn()
    with conn:
        conn.execute(DOC_TABLE_SQL)
    conn.close()

def safe_get(d, *keys, default=None):
    cur = d
    for k in keys:
        if isinstance(cur, dict) and k in cur:
            cur = cur[k]
        else:
            return default
    return cur

def extract_document_fields(resp_json, default_name=None):
    """
    ç¨³å¥æå– document_id ä¸ document_nameï¼Œå…¼å®¹ä»¥ä¸‹ç»“æ„ï¼š
      - {"id": "...", "name": "..."}
      - {"data": {"id": "...", "name": "..."}}
      - {"documents": [{"id": "...", "name": "..."}], "batch": "..."}  # ä½ çš„ç¤ºä¾‹
      - {"data": {"documents": [{"id": "...", "name": "..."}]}}
    """
    doc_id = None
    doc_name = None

    # é¡¶å±‚
    doc_id = (resp_json.get("id") or doc_id)
    doc_name = (resp_json.get("name") or doc_name)

    # data.*
    data = resp_json.get("data")
    if isinstance(data, dict):
        doc_id = data.get("id") or doc_id
        doc_name = data.get("name") or doc_name
        docs = data.get("documents")
        if isinstance(docs, list) and docs:
            first = docs[0] if isinstance(docs[0], dict) else None
            if first:
                doc_id = first.get("id") or doc_id
                doc_name = first.get("name") or doc_name

    # é¡¶å±‚ documents åˆ—è¡¨ï¼ˆç¤ºä¾‹ï¼‰
    docs = resp_json.get("documents")
    if isinstance(docs, list) and docs:
        first = docs[0] if isinstance(docs[0], dict) else None
        if first:
            doc_id = first.get("id") or doc_id
            doc_name = first.get("name") or doc_name

    if not doc_name and default_name:
        doc_name = default_name

    return doc_id, doc_name

def login_and_get_token(base_url, email, password, language='en-US'):
    url = f"{base_url}/login"
    payload = {"email": email, "password": password, "language": language, "remember_me": True}
    r = httpx.post(url, json=payload, timeout=30.0)
    r.raise_for_status()
    data = r.json()
    if data.get("result") == "success":
        return data["data"]["access_token"]
    raise RuntimeError(f"Login failed: {data}")

def get_dataset_id_by_key(key: str) -> str:
    conn = get_db_conn()
    try:
        cur = conn.cursor()
        cur.execute("SELECT value FROM knowledgebase WHERE key = ?", (key,))
        row = cur.fetchone()
        return row[0] if row else None
    finally:
        conn.close()

def find_doc_record_by_name(doc_name: str, kb_id: str):
    conn = get_db_conn()
    try:
        cur = conn.cursor()
        cur.execute("SELECT id, kb_id, doc_id, doc_name, file_id, file_name FROM kb_documents WHERE doc_name = ? AND kb_id = ? ORDER BY id DESC LIMIT 1", (doc_name, kb_id))
        row = cur.fetchone()
        if row:
            keys = ["id","kb_id","doc_id","doc_name","file_id","file_name"]
            return dict(zip(keys, row))
        return None
    finally:
        conn.close()

def insert_doc_record(kb_id: str, doc_id: str, doc_name: str, file_id: str, file_name: str):
    conn = get_db_conn()
    try:
        with conn:
            conn.execute(
                "INSERT INTO kb_documents (kb_id, doc_id, doc_name, file_id, file_name) VALUES (?, ?, ?, ?, ?)",
                (kb_id, doc_id, doc_name, file_id, file_name)
            )
    finally:
        conn.close()

def delete_doc_record_file(kb_id: str, doc_name: str, file_id: str, file_name: str):
    # ä»…æ›´æ–°æœ€è¿‘ä¸€æ¡åŒ¹é…è®°å½•çš„ file ä¿¡æ¯ï¼›ä¸æ”¹ doc_id/kb_id
    conn = get_db_conn()
    try:
        with conn:
            conn.execute(
                "DELETE FROM kb_documents WHERE id = (SELECT id FROM kb_documents WHERE kb_id=? AND doc_name=? ORDER BY id DESC LIMIT 1)",
                (kb_id, doc_name)
            )
    finally:
        conn.close()

def upload_file_for_update(access_token, base_url, file_path):
    headers = {"Authorization": f"Bearer {access_token}"}
    with open(file_path, "rb") as f:
        files = {"file": (os.path.basename(file_path), f)}
        resp = requests.post(f"{base_url}/files/upload", headers=headers, files=files, timeout=60)
    if resp.status_code not in (200,201):
        raise RuntimeError(f"æ–‡ä»¶ä¸Šä¼ å¤±è´¥ï¼š{resp.status_code} {resp.text}")
    data = resp.json()
    return data

def delete_document_by_file(access_token, base_url, dataset_id, document_id, file_id):
    headers = {"Authorization": f"Bearer {access_token}"}
    #payload = {"file_id": file_id}
    # ä¸åŒç‰ˆæœ¬è·¯å¾„å¯èƒ½ä¸åŒï¼Œè¿™é‡Œé‡‡ç”¨è¾ƒæ–°çš„ update-by-file è·¯å¾„ï¼ˆè‹¥ä½ çš„ç‰ˆæœ¬ä¸æ”¯æŒï¼Œè¯·è°ƒæ•´ä¸ºæ—§æ¥å£ï¼‰
    url = f"{base_url}/datasets/{dataset_id}/documents/{document_id}"
    resp = requests.delete(url, headers=headers, timeout=60)
    #if resp.status_code not in (200,202,204):
    #    raise RuntimeError(f"æ›´æ–°æ–‡æ¡£å¤±è´¥ï¼š{resp.status_code} {resp.text}")
    #return resp.json()

def update_document_by_text(access_token, base_url, dataset_id, document_id, text):
    headers = {"Authorization": f"Bearer {access_token}"}
    payload = {
        "text": text,
        "indexing_technique": "economy",   # æˆ– high_quality
        "process_rule": {"mode": "automatic"}
    }
    url = f"{base_url}/datasets/{dataset_id}/documents/{document_id}/update-by-text"
    resp = requests.post(url, headers=headers, json=payload, timeout=60)
    if resp.status_code not in (200,201,202):
        raise RuntimeError(f"æ›´æ–°æ–‡æ¡£å¤±è´¥ï¼š{resp.status_code} {resp.text}")
    return resp.json()

def add_new_document(access_token, base_url, dataset_id, file_path=None, text=None, doc_name=""):
    headers = {"Authorization": f"Bearer {access_token}"}
    file_id = None
    file_name = None

    if file_path:
        file_info = upload_file_for_update(access_token, base_url, file_path)
        file_info["mime_type"] = "application/pdf"
        file_id = file_info.get("id") or safe_get(file_info, "data", "id")
        file_info["file_ids"]= [file_id]
        info_list = {
            "data_source_type": "upload_file",
            "file_info_list": file_info
        }
        file_name = os.path.basename(file_path)
        print("âœ… ä¸Šä¼ æˆåŠŸ file_id=", file_id)

        # 2) åŠ å…¥çŸ¥è¯†åº“
        add_doc_payload = {
            #"indexing_technique": "economy",   # æˆ– high_qualityï¼ŒæŒ‰éœ€è°ƒæ•´
            "indexing_technique": "economy",
            "doc_form": "text_model",
            "data_source": {
                "type": "file",
                "file_ids": [file_id],
                "info_list": info_list
            },
            "process_rule": {"mode": "automatic"}
        }
        url = f"{base_url}/datasets/{dataset_id}/documents"
        resp = requests.post(url, headers=headers, json=add_doc_payload, timeout=60)
        if resp.status_code not in (200,201,202):
            raise RuntimeError(f"æ·»åŠ æ–‡æ¡£å¤±è´¥ï¼š{resp.status_code} {resp.text}")
        data = resp.json()
        doc_id, doc_name = extract_document_fields(data, default_name=file_name)
        return {"doc_id": doc_id, "doc_name": doc_name or file_name, "file_id": file_id, "file_name": file_name}

    elif text is not None:
        payload = {
            "indexing_technique": "economy",
            "doc_form": "text_model",
            "data_source": {
                "type": "text",
                "text": text
            },
            "process_rule": {"mode": "automatic"},
            "name": doc_name or "text_document"
        }
        url = f"{base_url}/datasets/{dataset_id}/documents"
        resp = requests.post(url, headers=headers, json=payload, timeout=60)
        if resp.status_code not in (200,201,202):
            raise RuntimeError(f"æ·»åŠ æ–‡æ¡£å¤±è´¥ï¼š{resp.status_code} {resp.text}")
        data = resp.json()
        doc_id, doc_name = extract_document_fields(data, default_name=file_name)
        return {"doc_id": doc_id, "doc_name": doc_name or "text_document", "file_id": None, "file_name": None}

    else:
        raise ValueError("add_new_document éœ€è¦ file_path æˆ– text è‡³å°‘ä¸€ä¸ª")

def main():
    parser = argparse.ArgumentParser(description="æŒ‰æ–‡æ¡£åç§°æ›´æ–° Dify çŸ¥è¯†åº“æ–‡æ¡£ï¼›åç§°ä¸å­˜åœ¨åˆ™æ–°å»ºå¹¶ç™»è®°åˆ°æœ¬åœ°è¡¨ã€‚")
    parser.add_argument("knowledgebase", type=str, help="æœ¬åœ° knowledgebase è¡¨ä¸­çš„ keyï¼Œç”¨äºå– dataset_id")
    parser.add_argument("--doc-name", required=True, help="æ–‡æ¡£åç§°ï¼ˆåœ¨æœ¬åœ°è¡¨ä¸­æ£€ç´¢ç”¨ï¼‰")
    group = parser.add_mutually_exclusive_group(required=True)
    group.add_argument("--file", dest="file_path", help="ç”¨äºæ›´æ–°/æ–°å»ºçš„æ–‡ä»¶è·¯å¾„")
    group.add_argument("--text", dest="text_content", help="ç”¨äºæ›´æ–°/æ–°å»ºçš„çº¯æ–‡æœ¬å†…å®¹")

    parser.add_argument("--base-url", default="http://localhost/console/api")
    parser.add_argument("--email", default="tei952@hotmail.com")
    parser.add_argument("--password", default="Zjhuen1915")
    args = parser.parse_args()

    # 1) åˆå§‹åŒ–è¡¨ï¼ˆè‹¥ä¸å­˜åœ¨åˆ™åˆ›å»ºï¼‰
    init_db()

    # 2) å– dataset_id
    dataset_id = get_dataset_id_by_key(args.knowledgebase)
    if not dataset_id:
        raise SystemExit(f"æœªåœ¨ knowledgebase è¡¨ä¸­æ‰¾åˆ° key={args.knowledgebase} çš„ dataset_id")

    # 3) ç™»å½•è·å– access_token
    access_token = login_and_get_token(args.base_url, args.email, args.password)

    # 4) æœ¬åœ°æŸ¥è¯¢æ–‡æ¡£æ˜¯å¦å­˜åœ¨
    rec = find_doc_record_by_name(args.doc_name, kb_id=dataset_id)

    if rec:
        # === æ›´æ–°è·¯å¾„ ===
        document_id = rec["doc_id"]
        print(f"ğŸ”„ æœ¬åœ°å·²å­˜åœ¨æ–‡æ¡£ï¼šdoc_name='{args.doc_name}', doc_id='{document_id}' â†’ æ‰§è¡Œæ›´æ–°")

        if args.file_path:
            # å…ˆä¸Šä¼ æ–°æ–‡ä»¶ï¼Œæ‹¿åˆ° file_id
            file_info = upload_file_for_update(access_token, args.base_url, args.file_path)
            file_id = file_info.get("id") or safe_get(file_info, "data", "id")
            # è°ƒç”¨æ›´æ–°æ¥å£
            delete_document_by_file(access_token, args.base_url, dataset_id, document_id, file_id)
            # æ›´æ–°æœ¬åœ°è®°å½•ä¸­çš„ file_id/file_nameï¼ˆä¾¿äºè¿½æº¯ï¼‰
            delete_doc_record_file(dataset_id, args.doc_name, file_id=file_id, file_name=os.path.basename(args.file_path))
            result = add_new_document(access_token, args.base_url, dataset_id, file_path=args.file_path, doc_name=args.doc_name)
            insert_doc_record(kb_id=dataset_id, doc_id=result["doc_id"] or "UNKNOWN", doc_name=result["doc_name"], file_id=result["file_id"], file_name=result["file_name"])

            print("âœ… æ›´æ–°æˆåŠŸï¼ˆæŒ‰æ–‡ä»¶ï¼‰ã€‚")
        else:
            data = update_document_by_text(access_token, args.base_url, dataset_id, document_id, args.text_content)
            print("âœ… æ›´æ–°æˆåŠŸï¼ˆæŒ‰æ–‡æœ¬ï¼‰ã€‚")

    else:
        # === æ–°å»ºè·¯å¾„ ===
        print(f"ğŸ†• æœ¬åœ°ä¸å­˜åœ¨æ–‡æ¡£å '{args.doc_name}' çš„è®°å½• â†’ æ‰§è¡Œæ–°å»º")
        if args.file_path:
            result = add_new_document(access_token, args.base_url, dataset_id, file_path=args.file_path, doc_name=args.doc_name)
            insert_doc_record(kb_id=dataset_id, doc_id=result["doc_id"] or "UNKNOWN", doc_name=result["doc_name"], file_id=result["file_id"], file_name=result["file_name"])
            print(f"âœ… æ–°å»ºæˆåŠŸå¹¶ç™»è®°ï¼šdoc_id={result['doc_id']}, name={result['doc_name']}")
        else:
            result = add_new_document(access_token, args.base_url, dataset_id, text=args.text_content, doc_name=args.doc_name)
            insert_doc_record(kb_id=dataset_id, doc_id=result["doc_id"] or "UNKNOWN", doc_name=result["doc_name"], file_id=None, file_name=None)
            print(f"âœ… æ–°å»ºæˆåŠŸå¹¶ç™»è®°ï¼šdoc_id={result['doc_id']}, name={result['doc_name']}")

if __name__ == "__main__":
    main()
