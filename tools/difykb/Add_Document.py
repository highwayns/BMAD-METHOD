#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Add_Document_enhanced.py
- åˆå§‹åŒ–æ—¶ï¼šè‹¥ä¸å­˜åœ¨æ–‡æ¡£æ•°æ®è¡¨åˆ™è‡ªåŠ¨åˆ›å»º
- æˆåŠŸå°†æ–‡ä»¶åŠ å…¥ Dify çŸ¥è¯†åº“åï¼šæŠŠæ–‡æ¡£åç§°ã€æ–‡æ¡£IDï¼ˆdocument_idï¼‰ã€çŸ¥è¯†åº“IDï¼ˆdataset_id/knowledgebase_idï¼‰ã€æ–‡ä»¶ID(file_id) ç­‰å†™å…¥æ–‡æ¡£æ•°æ®è¡¨
- å…¼å®¹ /console/api ä¸ /v1 é£æ ¼ï¼Œä»ä½¿ç”¨åŸè„šæœ¬çš„ç™»å½•ä¸ä¸Šä¼ é€»è¾‘
"""
import os
import argparse
import sqlite3
from datetime import datetime
import requests
import httpx

# === é…ç½®åŒº ===
KBDB_PATH = "/home/tei952/sayama/00.standard_and_tool/standards/ai_poc/AI_Powered_system_manager/project_data/project_config.db"

DOC_TABLE_SQL = """
CREATE TABLE IF NOT EXISTS kb_documents (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    kb_id TEXT NOT NULL,
    doc_id TEXT NOT NULL,
    doc_name TEXT,
    file_id TEXT,
    file_name TEXT,
    created_at TEXT DEFAULT (datetime('now'))
);
"""

def get_db_conn():
    os.makedirs(os.path.dirname(KBDB_PATH), exist_ok=True)
    conn = sqlite3.connect(KBDB_PATH)
    return conn

def init_db():
    try:
        conn = get_db_conn()
        with conn:
            conn.execute(DOC_TABLE_SQL)
        conn.close()
        print("âœ… æ–‡æ¡£æ•°æ®è¡¨æ£€æŸ¥/åˆ›å»ºå®Œæˆï¼škb_documents")
    except Exception as e:
        print(f"âŒ æ–‡æ¡£æ•°æ®è¡¨åˆå§‹åŒ–å¤±è´¥: {e}")

def get_knowledgebase_value(key: str) -> str:
    """
    æ ¹æ® key ä» knowledgebase è¡¨ä¸­æŸ¥è¯¢ valueï¼ˆçŸ¥è¯†åº“IDï¼‰ã€‚
    """
    try:
        conn = get_db_conn()
        cursor = conn.cursor()
        cursor.execute('SELECT value FROM knowledgebase WHERE key = ?', (key,))
        row = cursor.fetchone()
        conn.close()
        if row:
            return row[0]
        else:
            print(f"âš ï¸ æœªæ‰¾åˆ° key='{key}' å¯¹åº”çš„çŸ¥è¯†åº“è®°å½•ã€‚")
            return None
    except Exception as e:
        print(f"âŒ æŸ¥è¯¢çŸ¥è¯†åº“IDå¤±è´¥ï¼š{e}")
        return None

def login_and_get_token(base_url, email, password, language='en-US'):
    url = f"{base_url}/login"
    payload = {
        "email": email,
        "password": password,
        "language": language,
        "remember_me": True
    }
    r = httpx.post(url, json=payload, timeout=30.0)
    r.raise_for_status()
    data = r.json()
    if data.get("result") == "success":
        return {
            "access_token": data["data"]["access_token"],
            "refresh_token": data["data"]["refresh_token"]
        }
    raise RuntimeError(f"Login failed: {data}")

def safe_get(d, *keys, default=None):
    cur = d
    for k in keys:
        if isinstance(cur, dict) and k in cur:
            cur = cur[k]
        else:
            return default
    return cur

def extract_document_fields(resp_json, default_name=None):
    """
    ç¨³å¥æå– document_id ä¸ document_nameï¼Œå…¼å®¹ä»¥ä¸‹ç»“æ„ï¼š
      - {"id": "...", "name": "..."}
      - {"data": {"id": "...", "name": "..."}}
      - {"documents": [{"id": "...", "name": "..."}], "batch": "..."}  # ä½ çš„ç¤ºä¾‹
      - {"data": {"documents": [{"id": "...", "name": "..."}]}}
    """
    doc_id = None
    doc_name = None

    # é¡¶å±‚
    doc_id = (resp_json.get("id") or doc_id)
    doc_name = (resp_json.get("name") or doc_name)

    # data.*
    data = resp_json.get("data")
    if isinstance(data, dict):
        doc_id = data.get("id") or doc_id
        doc_name = data.get("name") or doc_name
        docs = data.get("documents")
        if isinstance(docs, list) and docs:
            first = docs[0] if isinstance(docs[0], dict) else None
            if first:
                doc_id = first.get("id") or doc_id
                doc_name = first.get("name") or doc_name

    # é¡¶å±‚ documents åˆ—è¡¨ï¼ˆç¤ºä¾‹ï¼‰
    docs = resp_json.get("documents")
    if isinstance(docs, list) and docs:
        first = docs[0] if isinstance(docs[0], dict) else None
        if first:
            doc_id = first.get("id") or doc_id
            doc_name = first.get("name") or doc_name

    if not doc_name and default_name:
        doc_name = default_name

    return doc_id, doc_name

def record_document(kb_id: str, doc_id: str, doc_name: str, file_id: str, file_name: str):
    try:
        conn = get_db_conn()
        with conn:
            conn.execute(
                'INSERT INTO kb_documents (kb_id, doc_id, doc_name, file_id, file_name) VALUES (?, ?, ?, ?, ?)',
                (kb_id, doc_id, doc_name, file_id, file_name)
            )
        conn.close()
        print(f"ğŸ—‚ï¸ å·²å†™å…¥æ–‡æ¡£è®°å½•ï¼škb_id={kb_id}, doc_id={doc_id}, doc_name={doc_name}, file_id={file_id}")
    except Exception as e:
        print(f"âŒ å†™å…¥æ–‡æ¡£æ•°æ®è¡¨å¤±è´¥ï¼š{e}")

def upload_and_add_to_dataset(access_token, dataset_id, file_path, base_url="http://localhost/console/api"):
    headers = {"Authorization": f"Bearer {access_token}"}

    # 1) ä¸Šä¼ æ–‡ä»¶
    with open(file_path, "rb") as f:
        files = {"file": (os.path.basename(file_path), f)}
        upload_resp = requests.post(f"{base_url}/files/upload", headers=headers, files=files, timeout=60)
    if upload_resp.status_code not in (200, 201):
        print("âŒ æ–‡ä»¶ä¸Šä¼ å¤±è´¥:", upload_resp.status_code, upload_resp.text)
        return False

    file_info = upload_resp.json()
    file_info["mime_type"] = "application/pdf"
    file_id = file_info.get("id") or safe_get(file_info, "data", "id")
    file_info["file_ids"]= [file_id]
    info_list = {
        "data_source_type": "upload_file",
        "file_info_list": file_info
    }
    file_name = os.path.basename(file_path)
    print("âœ… ä¸Šä¼ æˆåŠŸ file_id=", file_id)

    # 2) åŠ å…¥çŸ¥è¯†åº“
    add_doc_payload = {
        #"indexing_technique": "economy",   # æˆ– high_qualityï¼ŒæŒ‰éœ€è°ƒæ•´
        "indexing_technique": "economy",
        "doc_form": "text_model",
        "data_source": {
            "type": "file",
            "file_ids": [file_id],
            "info_list": info_list
        },
        "process_rule": {"mode": "automatic"}
    }
    add_resp = requests.post(
        f"{base_url}/datasets/{dataset_id}/documents",
        headers=headers,
        json=add_doc_payload,
        timeout=60
    )
    print("ğŸ“¨ åŠ å…¥çŸ¥è¯†åº“å“åº”:", add_resp.status_code)

    if add_resp.status_code not in (200, 201, 202):
        print("âŒ æ·»åŠ æ–‡æ¡£å¤±è´¥:", add_resp.text)
        return False

    data = add_resp.json()
    print("ğŸ“„ æ–‡æ¡£æ·»åŠ å“åº”æ•°æ®:", data)
    # å…¼å®¹å¤šç§è¿”å›ç»“æ„ï¼Œå°½åŠ›æ‹¿åˆ° document_id / name
    doc_id, doc_name = extract_document_fields(data, default_name=file_name)
    if not doc_id:
        doc_id = safe_get(data, "data", "documents", 0, "id")
        doc_name = doc_name or safe_get(data, "data", "documents", 0, "name") or file_name

    if not doc_id:
        print("âš ï¸ æœªèƒ½ä»å“åº”ä¸­è§£æåˆ° document_idï¼Œå°†ä»…è®°å½• file_id ä¸æ–‡ä»¶åã€‚")

    # å†™å…¥æœ¬åœ°æ–‡æ¡£æ•°æ®è¡¨
    record_document(kb_id=dataset_id, doc_id=doc_id or "UNKNOWN", doc_name=doc_name, file_id=file_id, file_name=file_name)
    print("âœ… æ–‡æ¡£å·²æ·»åŠ åˆ°çŸ¥è¯†åº“ï¼Œå¹¶å†™å…¥æœ¬åœ°æ•°æ®è¡¨ã€‚")
    return True

def main():
    parser = argparse.ArgumentParser(description="å°†æ–‡ä»¶ä¸Šä¼ å¹¶åŠ å…¥ Dify çŸ¥è¯†åº“ï¼ŒåŒæ—¶è®°å½•åˆ°æœ¬åœ°æ–‡æ¡£æ•°æ®è¡¨ã€‚")
    parser.add_argument("knowledgebase", type=str, help="æœ¬åœ° knowledgebase è¡¨ä¸­é…ç½®çš„ keyï¼ˆç”¨äºå– dataset_idï¼‰")
    parser.add_argument("filepath", type=str, help="è¦åŠ å…¥çŸ¥è¯†åº“çš„æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--base-url", default="http://localhost/console/api", help="Dify åå°åŸºç¡€ URLï¼Œå¦‚ http://localhost/console/api æˆ– http://localhost/v1")
    parser.add_argument("--email", default="tei952@hotmail.com")
    parser.add_argument("--password", default="Zjhuen1915")
    args = parser.parse_args()

    # 1) åˆå§‹åŒ–è¡¨
    init_db()

    # 2) ç™»å½•å– token
    tokens = login_and_get_token(
        base_url=args.base_url,
        email=args.email,
        password=args.password
    )
    access_token = tokens["access_token"]
    print("ğŸ”‘ Access Token è·å–æˆåŠŸ")

    # 3) è§£æçŸ¥è¯†åº“ID
    dataset_id = get_knowledgebase_value(args.knowledgebase)
    if not dataset_id:
        raise SystemExit("æœªè·å–åˆ°çŸ¥è¯†åº“IDï¼Œç»ˆæ­¢ã€‚")

    # 4) å•æ–‡ä»¶å¤„ç†
    filepath = args.filepath
    if not os.path.isfile(filepath):
        raise SystemExit(f"æ–‡ä»¶ä¸å­˜åœ¨ï¼š{filepath}")
    print("ğŸ“„ æ­£åœ¨å¤„ç†æ–‡ä»¶ï¼š", filepath)

    ok = upload_and_add_to_dataset(access_token, dataset_id, filepath, base_url=args.base_url)
    if ok:
        print(f"ğŸ‰ å®Œæˆï¼šå·²åŠ å…¥çŸ¥è¯†åº“å¹¶è®°å½•åˆ°è¡¨ kb_documents ï¼š{filepath}")
    else:
        print("ç»“æŸï¼šæœªæˆåŠŸåŠ å…¥çŸ¥è¯†åº“ã€‚")

if __name__ == "__main__":
    main()
